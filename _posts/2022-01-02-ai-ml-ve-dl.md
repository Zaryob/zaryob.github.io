---
layout: post
title: "Yanlış Bilinenleri ile: AI ML ve DL"
date: 2021-11-26 12:23:43 +0300
categories: [genel, internet]
image: "2022-01-02-ai-ml-ve-dl.jpeg"
image_hash: "1f6855400683c5fb0afd7e248fd1c0a1"
---

AI veya yapay zeka dediğimiz zaman insanların aklına pek çok bilim kurgu filmi ile paralel şeyler geliyor. Çocukluğumuzdaki Jetgiller hayranlığı mı yoksa Hollywood’un abartı safsataları mı bilinmez ama yapay zeka şu an bilgisayar dünyasının kutsal bir miti gibi görülüyor. Kimileri yapay zekaya çok büyük anlamlar yükleyerek, yapay zeka bizi yokedecekmiş efsaneleri uydururken, kimileri “ben yapay zeka biliyorum” demek için çeşitli dil kütüphanelerinin örnek kodlarını alıp çalıştırıp linkedin üzerinden yapay zeka konusunda atıp tutan postlar paylaşıyor. Ancak naçizane gördüğüm şey pek çok kişi başlıkta geçen terimleri birbirine bulamaç etmek suretiyle işte bu yapay zeka diyor.

Şimdi hep beraber bu işe biraz daha detaylı bir şekilde eğilerek inceleyelim.

Artifical Intelligence — Yapay Zeka
===================================

Zeka, bir varlığın nesnel gerçekleri algılama, kavrama ve çıkarımlar yapma yeteneğidir.

![](https://miro.medium.com/max/20000/1*QHSpKVS5QQTdpVz0ez_chw.gif)

Zeka, insanlar ve hayvanlarda biyolojik olarak sağlanır. Beyin bir donanım, bilinç ise bu donanımın içerisindeki yazılım gibi düşünülürse; beyine gönderilen her yeni girdi, beyin içerisinde elektriksel sinyaller olarak iletilip, işlenerek bir sonraki tecrübe için çıkarımda bulunabilme yeteneği sağlamak amacıyla depolanır.

Yapay zeka ise bu işlemin makineler tarafından yapılmasıdır. Sorun çözme, iletişim kurma, çıkarımsama yapma ve karar verme gibi yüksek bilişsel fonksiyonları veya otonom davranışları sergilemesi beklenen yazılımlar yapay zeka yazılımları olarak adlandırılır. Yapay zeka, doğal zekanın matematiksel fonksiyonlar kullanılarak makineler tarafından davranışlardan çıkarımlar üreterek sonraki adımlarında aslında bu temeli kullanarak hareketlerde bulunur.

Yapay zeka geçmişi itibariyle felsefede Aristo’dan beri yer bulmuştur. Aristo’nun **syllogism** metodu, mekanik düşünce yeteneğininin temel motivasyonu olmuşken, bilgisayarların düşünebileceğine dair ilk teori modern bilgisayarların babası olarak da bilinen Alan Turing tarafından atılmıştır.

2\. Dünya Savaşında, Naziler tarafından kullanılan Enigma algoritmasını çözmek için çalışan matematikçiler, 1940'lı yıllarda bu şifreleri çözmek için ürettikleri Kripto analiz cihazları ile gerek modern bilgisayarların gerekse yapay zekanın temelini atmışlardır. O zamana kadar doğrusal işlemler yapmak için kullanılan aritmetik işlem ünitelerinin (ALU) karmaşık işlemler yapıp yapamayacağına dair araştırmalar hep merak kaynağı olmuştu.

![](https://miro.medium.com/max/20000/0*rLOhf_-yVpZn9VSr)

İşte tam bu dönemde ünlü matematikçi Alan Turing iki önemli çalışması ile bilgisayarların geleceğine imza attı. İlki karmaşık problemlerin hesaplanmasına dair yazdığı “Saptama Problemi Hakkında Bir Uygulamayla Birlikte Hesaplanabilir Sayılar” makalesinde problem çözümüne yönelik ürettiği sanal makinedir. Bu makine ile teorik ve matematiksel temellere dayalı olarak, her türlü matematiksel hesabın yapılabileceği Turing tarafından iddia edilmişti.

![](https://miro.medium.com/max/2000/0*YSFaPCjywv3mrlEW.png)

Diğer önemli çalışması ise Turing testidir. Turing kendi kurguladığı bilişsel deneyde şunu iddia etmişti. Makineler ile insanların kendi arasında yazıyla konuşacağı bir ortamda, herhangi bir duygusal geribildirim almaksızın bir insan sorular sorar ve karşı taraf ise sorularına cevap verir. Herhangi bir ek iletişim olmaksızın ve karşı tarafa insan olup olmadığı sorulmaksızın yapılan bu teste Turing Testi denilmekte. Turing testinin amacı, bir makinenin düşünebildiğini söyleyebilmenin mantıksal olarak mümkün olup olmadığıdır. Eğer bir makine soru soran kişi tarafından insan olduğu değerlendirilirse, bu durumda bu makine Turing Testini geçmiş demektir, yani düşünebilmektedir.

1950 ve sonrasındaki tüm bilgisayar çalışmaları aslında bu iki çalışmayı temel almaktadır. 1956 yılında, Dartmouth Yaz Araştırma Projesi ile, bir avuç matematikçi düşünen makineler konusunda fikirlerini açıklığa kavuşturmak ve geliştirmek için bir grup kurmaya karar verdi. Bu grup tamamen yeni bir bilimsel alana yönelecekti ve bu yeni alan için ise ‘Yapay Zeka’ adı seçildi.

1960'ların sonuna geldiğimizde ise yapay zeka alanına dair değişik bir fikir ortaya atıldı. Zeka daha öncesinde belirttiğim gibi beyin üzerinde yer alan bilincin bir alt özelliği. Buradan hareketle Arthur Samuel yeni bir metod geliştirildi ve bu da tam olarak Makine Öğrenmesi dediğimiz konu.

**Machine Learning — Makine Öğrenmesi**
=======================================

![](https://miro.medium.com/max/20002/1*CRAKEE_bQ_sohQP3eXMwwQ.png)

Bilgisayarlar kendilerine atanan basit görevler için, makineye eldeki sorunu çözmek için gereken tüm adımları nasıl uygulayacağını bildiren algoritmalar ile programlanırlar. Böylece siz bir defa örneğin bir matriks çarpma işlemini programlar ve bundan sonra yapılacak her matriks işleminde sadece matriksi girerek sonuç alırsınız. Bu tip basit işlerin bilgisayar tarafında öğrenilmesine gerek yoktur. Ancak bu yöntemde daha gelişmiş görevler için gerekli algoritmaları elle oluşturmak çok zordur. Beyin ise bu tip şeyleri yapmak için biyolojik olarak yeni nöral bağlar kurar ve böylece bir işlemi bir defa öğrendikten sonra onun bir modelini beyinde tutarak işe yarayacağı zaman tekrar kullanır.

![](https://miro.medium.com/max/2000/0*Pp9kg5c7lo5YUaB5)

İşte bundan hareketler Arthur Samuel tarafından şu ortaya atıldı. Biz elimizdeki makineyi bir dama oyununa dair örnekler ile yeteri kadar beslersek, belirli bir yerden sonra bu makine kendi kendine dama oynayacak hale gelecektir. Veya biz bu makineyi yeterince köpek fotoğrafı ile beslersek, fotoğraftaki bir köpeği algılayabilecektir. (yandaki fotoğrafta görüldüğü üzere 😂)

Bütünü ile makine öğrenmesinin temeli istatistik bilimine dayanır. Yaptığımız şey istatistiksel olarak bize verilen örneklerden istatistik modelleri çıkartmak ve bu modelleri deneyimleyip, genelleme yapmaktır. Her deneyim genelleme amacıyla kullanılacak yeni bir hesap çıkarır. Bu hesapların tamamı model olarak adlandırılır. Modeller makine öğrenmesi için her şeydir diyebiliriz.

Her ne kadar AI altında düşünen makineler oluşturma amacıyla yola çıkmış bir alt dal olsa dahi, makine öğrenmenin mantıksal, bilgi tabanlı yaklaşımı, yapay zeka ve makine öğrenimi arasında bir çatlağa neden oldu. Çünkü AI daha sezgisel yaklaşırken, makine öğrenmesi daha istatistiksel olan yaklaşımı sebebiyle, yapay zeka ile makine öğrenmesinin birbiri ile kesişen iki farklı metodoloji olarak da görülmektedir.

Deep Learning — Derin Öğrenme
=============================

![](https://miro.medium.com/max/20000/1*GGV7JZjMyBsVXeaZ2PPGlw.png)

İlk makine öğrenimi çalışmaları daha karmaşık işlemler silsilesini hedef alarak geliştirildi. Ve onlarca yıl boyunca basit işleri bile makineye öğretmesi kalabalık bir takım işlemler olmaya devam etti. Peki neden makineler bu kadar öğrenemez durumdayken insan beyni bu kadar çabuk öğrenebiliyor.

Beyin bu deneyimleri daha öncesinde söylediğim gibi birbirine bağlı nöronlar ile yapar, her yeni deneyimde yeni nöral bağlar kurulur veya zayıflar. Böylece beyin kendisini her bir olay için değiştirir.

Derin öğrenme kısaca bu yöntemi bunu esas alır.

Yapay sinir ağları , beynimizin biyolojisine dair anlayışımızdan ilham alır, yapay nöronlar arasındaki deneyimden oluşan bağlantılar kurulur. Ancak, herhangi bir nöronun belirli bir fiziksel mesafe içinde başka bir nörona bağlanabildiği biyolojik bir beyinden farklı olarak, bu yapay sinir ağlarının ayrı katmanları, bağlantıları ve veri yayılım yönleri vardır.

Örneğin, bir görüntü alabilir, onu sinir ağının ilk katmanına girilen bir grup karoya bölebilirsiniz. İlk katmanda bireysel nöronlar, ardından verileri ikinci bir katmana iletir. İkinci nöron katmanı görevini yapar ve son katman ve nihai çıktı üretilene kadar bu böyle devam eder.

Her nöron girdisine bir ağırlık verir — gerçekleştirilen göreve göre ne kadar doğru veya yanlış olduğu. Nihai çıktı daha sonra bu ağırlıkların toplamı tarafından belirlenir. Dur işareti örneğimizi düşünün. Dur işareti görüntüsünün nitelikleri nöronlar tarafından kesilir ve sekizgen şekli, itfaiye aracının kırmızı rengi, ayırt edici harfleri, trafik işareti boyutu ve hareketi veya eksikliği gibi “incelenir”. Sinir ağının görevi, bunun bir dur işareti olup olmadığına karar vermektir.

Bu kararlar “olasılık vektörü” ile ortaya çıkar, ağırlıklandırmaya dayalı, gerçekten oldukça eğitimli bir tahmin olarak karşımıza çıkar. Örneğimizde sistem görüntünün dur işareti olduğundan %86, hız sınırı işareti olduğundan %7 ve ağaca saplanmış bir uçurtma olduğundan %5 emin olabilir ve bu böyle devam eder ve ağ mimarisi daha sonra bu çıktının doğru olup olmadığını söyler, böylece her bir adımdan yeni bir sonuç çıkmış olur.

Derin öğrenme neredeyse makine öğrenmesi ile aynı zamanda çıkmasına rağmen yapay zeka araştırmacıları yapay sinir ağlarından neredeyse tamamen kaçınıyordu. Temel sorun ise, en temel sinir ağlarının bile hesaplama açısından çok yoğun olmasıydı, bu sadece olayın pratik bir yaklaşım oluşundan uzaklaştırmıyor, ayrıca çok büyük maaliyetler çıkartıyordu.

Yine de, Toronto Üniversitesi’nden Geoffrey Hinton liderliğindeki küçük bir sapkın grubu, 1990'larda derin öğrenmenin süper bilgisayarların çalıştıracağı algoritmaları paralel hale getirerek kavramı kanıtladı. Böylece derin öğrenme konusunda daha detaylı çalışma yapılabilme azmi geldi. Ancak asıl dananın kuyruğunun kopuşu ise GPU’ların potansiyellerinin keşfi ile oldu.

GPU, grafiksel hesaplama ve videoların işlenmesi için özel hesaplamaları işlemede kullanılan bir işlemcidir. Bunu, genel hesaplamaları işlemede kullandığımız CPU ile karşılaştırabiliriz. CPU’lar, günlük kullandığımız cihazlarda gerçekleştirilen hesaplamaların çoğuna güç sağlar. CPU içerisindeki ALU, basit aritmetik hesaplamalarda hızlı iken genellikle matriks hesaplamasında ve paralel işlem kaabiliyetinde yapısı gereği çok daha yavaş kalmaktadırlar. CISC mimarisindeki işlemciler bu paralel hesaplama ve matriks işlemleri için daha optimize yöntemler getirse bile GPU, bu görevleri tamamlamada hala CPU’dan daha hızlı olabilir. GPU’lar, paralel olarak çalıştırılabilen görevlerde mükemmeldir, özellikle çoklu çekirdek özelliği sayesinde derin öğrenmede kullandığımız paralel yapay sinirler ile çok esnek yapay sinir ağları kurabilmekteyiz.

Gelecek
=======

Aslında çok da uzak olmayan bir gelecek var. Ve biz de bu geleceğin an itibariyle içerisindeyiz.

Pek çok donanımı en optimal şeklinde kullanabilmemiz için yapay zeka örneklerini hayatımızın içinde görmekteyiz. Örneğin dijital kameralarda elimizdeki küçük alandaki donanımı 8K veya 12K’ya yükseltmek için kullanmakta, oyunlarda grafik kaplamalarını daha az kaynak kullanarak elde etmek veya daha basit bir örnekle önceki postlarımdan birisinde anlattığım Github CoPilot gibi çözümlerde kullanmaktayız.

Bununla beraber erken uyarı sistemleri, şehir planlaması ve trafik haritalandırması gibi işlemlerden tutun uçakların otopilotlarına kadar pek çok alanlarda çoktandır yapay zeka teknikleri kullanılmakta. Boeing 737M gibi başarısız örneklerini gördüğümüz gibi çok başarılı örneklerini de görmekteyiz.

Ancak şunu göz önünden uzak tutmamak gerekir. Bugün yapay zeka olarak tanımladığımız şey aslında makinelerin önemli konularda insan desteği olmaksızın kendi kararlarını alabilmesidir. Bunun ise arkasında tamamiyle istatistik ve olasılık biliminin incelikleri yatmakta. Yani bilip bilmeden abarttığımız şey aslında bir programlama yöntemi. Ve onu abartmamız gereken tek konu bence istatistik ve olasılığın makineye düşünebilme yeteneği katabilecek bilimler oluşunun şaşırtıcılığıdır.

Peki Yapay Zeka dünyayı ele geçirebilir mi? Neden olmasın, nitekim Olasılık dahilinde…
